{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2TX5k886RFGw/UBJ9N+zG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuentsa/cloud-data-tools/blob/main/runtastic_data/extract_and_load_adidas_running_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Global attributes\n",
        "# We will retrieve these specific top-level fields from each sport session file\n",
        "top_level_fields = [\n",
        "    \"version\", \"duration\", \"pause\", \"calories\", \"dehydration_volume\",\n",
        "    \"start_time_timezone_offset\", \"end_time_timezone_offset\", \"start_time\",\n",
        "    \"end_time\", \"created_at\", \"updated_at\", \"id\", \"sport_type_id\"\n",
        "]\n",
        "# Each sport session has a list of features. We will load only the following ones\n",
        "features_to_load = [\"weather\", \"map\", \"track_metrics\", \"initial_values\"]\n",
        "supported_feature_attributes = [\"temperature\", \"wind_speed\", \"wind_direction\",\n",
        "                                \"humidity\", \"start_latitude\", \"start_longitude\",\n",
        "                                \"distance\", \"average_speed\", \"average_pace\",\n",
        "                                \"max_speed\", \"elevation_gain\", \"elevation_loss\", \"distance\", \"duration\"]\n",
        "# We will save and unzip  the  runtastic file here.\n",
        "work_dir = \"/home/runtastic/\"\n",
        "\n",
        "# Extract the connection string from the notebook secrets\n",
        "conn_string = userdata.get('postgres_conn_string')\n",
        "\n",
        "# This File ID is the identifier of your zip file stored in Google Drive\n",
        "# Oonce you store the zip file in Google drive, retrieve its identifier to store it as secrets in Google Colab\n",
        "# It should look like this laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "runtastic_file_id = userdata.get('runtastic_file_id') # TODO add this file id in a secret"
      ],
      "metadata": {
        "id": "Qbt5Yp0k48wn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Connect to Postgres DB and Create Table to Load Extracted Data\n",
        "# A database connection is needed to load all data extracted from runtastic files\n",
        "# We also create all required tables if not already exist\n",
        "\n",
        "import psycopg2\n",
        "from google.colab import userdata\n",
        "import psycopg2\n",
        "conn_string = userdata.get('postgres_conn_string')\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cur = conn.cursor()\n",
        "    print(\"Successfully connected to a postgres instance and database\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Database connection failed: {e}\")\n",
        "\n",
        "# Store all sport sessions loaded from the zip file\n",
        "sessions_table = \"sessions\"\n",
        "# Store all fastest loaded from each sport session\n",
        "fastest_segments_table = \"fastest_segments\"\n",
        "\n",
        "# Create the session table if not exist\n",
        "\n",
        "create_table_sql = \"\"\"\n",
        "DROP TABLE sport_type CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS sport_type (\n",
        "  id INT PRIMARY KEY,\n",
        "  activity VARCHAR(255)\n",
        ");\n",
        "DROP TABLE sessions;\n",
        "CREATE TABLE IF NOT EXISTS sessions (\n",
        "  version FLOAT,\n",
        "  duration FLOAT,\n",
        "  pause FLOAT,\n",
        "  calories FLOAT,\n",
        "  dehydration_volume FLOAT,\n",
        "  start_time_timezone_offset FLOAT,\n",
        "  end_time_timezone_offset FLOAT,\n",
        "  start_time TIMESTAMP WITH TIME ZONE,\n",
        "  end_time TIMESTAMP WITH TIME ZONE,\n",
        "  created_at TIMESTAMP WITH TIME ZONE,\n",
        "  updated_at TIMESTAMP WITH TIME ZONE,\n",
        "  id VARCHAR(255) PRIMARY KEY,\n",
        "  sport_type_id INT REFERENCES sport_type(id),\n",
        "  temperature FLOAT,\n",
        "  wind_speed FLOAT,\n",
        "  wind_direction FLOAT,\n",
        "  humidity FLOAT,\n",
        "  start_latitude FLOAT,\n",
        "  start_longitude FLOAT,\n",
        "  distance FLOAT,\n",
        "  average_speed FLOAT,\n",
        "  average_pace FLOAT,\n",
        "  max_speed FLOAT,\n",
        "  elevation_gain FLOAT,\n",
        "  elevation_loss FLOAT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# TODO Create the table to store the fastest_segments\n",
        "try:\n",
        "    # Execute the CREATE TABLE statement\n",
        "    cur.execute(create_table_sql)\n",
        "    # Commit the changes and close the connection\n",
        "    conn.commit()\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "    print (\"All Tables created successfully\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"failed to create the sessions table: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RmBAdS7swdL_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save in Postgres the static list of Runtastic Sport Types\n",
        "sport_type_sql = \"\"\"\n",
        "INSERT INTO sport_type (id, activity)\n",
        "SELECT *\n",
        "FROM (\n",
        "  VALUES\n",
        "  (1, 'Running'),\n",
        "  (62, 'Speed Skiing'),\n",
        "  (2, 'Nordic Walking'),\n",
        "  (63, 'PushUps'),\n",
        "  (3, 'Cycling'),\n",
        "  (64, 'SitUps'),\n",
        "  (4, 'Mountain Biking'),\n",
        "  (65, 'PullUps'),\n",
        "  (5, 'Other'),\n",
        "  (66, 'Squats'),\n",
        "  (6, 'Inline Skating'),\n",
        "  (7, 'Hiking'),\n",
        "  (68, 'Baseball'),\n",
        "  (8, 'Cross-country skiing'),\n",
        "  (69, 'Crossfit'),\n",
        "  (9, 'Skiing'),\n",
        "  (70, 'Dancing'),\n",
        "  (10, 'Snowboarding'),\n",
        "  (71, 'Ice Hockey'),\n",
        "  (11, 'Motorbike'),\n",
        "  (72, 'Skateboarding'),\n",
        "  (13, 'Snowshoeing'),\n",
        "  (73, 'Zumba'),\n",
        "  (14, 'Treadmill'),\n",
        "  (74, 'Gymnastics'),\n",
        "  (15, 'Ergometer'),\n",
        "  (75, 'Rugby'),\n",
        "  (16, 'Elliptical'),\n",
        "  (76, 'Standup Paddling'),\n",
        "  (17, 'Rowing'),\n",
        "  (77, 'Sixpack'),\n",
        "  (18, 'Swimming'),\n",
        "  (78, 'Butt Training'),\n",
        "  (19, 'Walking'),\n",
        "  (80, 'Leg Training'),\n",
        "  (20, 'Riding'),\n",
        "  (81, 'Results Workout'),\n",
        "  (21, 'Golfing'),\n",
        "  (82, 'Trail Running'),\n",
        "  (22, 'Race Cycling'),\n",
        "  (84, 'Plogging'),\n",
        "  (23, 'Tennis'),\n",
        "  (85, 'Wheelchair'),\n",
        "  (24, 'Badminton'),\n",
        "  (86, 'E Biking'),\n",
        "  (25, 'Squash'),\n",
        "  (87, 'Scootering'),\n",
        "  (26, 'Yoga'),\n",
        "  (88, 'Rowing Machine'),\n",
        "  (27, 'Aerobics'),\n",
        "  (89, 'Stair Climbing'),\n",
        "  (28, 'Martial Arts'),\n",
        "  (90, 'Jumping Rope'),\n",
        "  (29, 'Sailing'),\n",
        "  (91, 'Trampoline'),\n",
        "  (30, 'Windsurfing'),\n",
        "  (92, 'Bodyweight Training'),\n",
        "  (31, 'Pilates'),\n",
        "  (93, 'Tabata'),\n",
        "  (32, 'Rock Climbing'),\n",
        "  (94, 'Callisthenics'),\n",
        "  (33, 'Frisbee'),\n",
        "  (95, 'Suspension Training'),\n",
        "  (34, 'Strength Training'),\n",
        "  (96, 'Powerlifting'),\n",
        "  (35, 'Volleyball'),\n",
        "  (97, 'Olympic Weightlifting'),\n",
        "  (36, 'Handbike'),\n",
        "  (98, 'Stretching'),\n",
        "  (37, 'Cross Skating'),\n",
        "  (99, 'Mediation'),\n",
        "  (38, 'Soccer'),\n",
        "  (100, 'Bouldering'),\n",
        "  (42, 'Surfing'),\n",
        "  (101, 'Via Ferrata'),\n",
        "  (43, 'Kitesurfing'),\n",
        "  (102, 'Pade'),\n",
        "  (44, 'Kayaking'),\n",
        "  (103, 'Pole Dancing'),\n",
        "  (45, 'Basketball'),\n",
        "  (104, 'Boxing'),\n",
        "  (46, 'Spinning'),\n",
        "  (105, 'Cricket')\n",
        ") AS new_data (id, activity)\n",
        "WHERE NOT EXISTS (\n",
        "  SELECT 1\n",
        "  FROM sport_type\n",
        "  WHERE id = new_data.id\n",
        ")\n",
        "\"\"\"\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cur = conn.cursor()\n",
        "    # Execute the CREATE TABLE statement\n",
        "    cur.execute(sport_type_sql)\n",
        "    # Commit the changes and close the connection\n",
        "    conn.commit()\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "    print (\"Sport Types initialized successfully\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"failed to initialize the sport type: {e}\")"
      ],
      "metadata": {
        "id": "LDYdUYtmNf9H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Authenticate to  Google Drive and download the file.\n",
        "\n",
        "from pickle import TRUE\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "\n",
        "downloaded_file = drive.CreateFile({'id': file_id})\n",
        "\n",
        "os.makedirs(work_dir, exist_ok=TRUE)\n",
        "file_path = os.path.join(work_dir, \"runtastic_data_export.zip\")\n",
        "downloaded_file.GetContentFile(file_path)\n"
      ],
      "metadata": {
        "id": "dlYlkFRkK32Y",
        "cellView": "form"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Unzip the data\n",
        "# Extract all files from the downloaded archive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "#   Recursively displays the folders beneath a specific folder in hierarchical way.\n",
        "def display_folders(folder_path, indent=0):\n",
        "  # Get all subfolders and files in the current folder\n",
        "  subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
        "  files = [f for f in os.listdir(folder_path) if not os.path.isdir(os.path.join(folder_path, f))]\n",
        "\n",
        "  # Print the current folder name with indentation\n",
        "  print(\" \" * indent + folder_path)\n",
        "  # Recursively display subfolders\n",
        "  for subfolder in subfolders:\n",
        "    display_folders(os.path.join(folder_path, subfolder), indent + 2)\n",
        "\n",
        "# Open the zip file and extract it\n",
        "zipobject = zipfile.ZipFile(file_path)\n",
        "# Unzip all files in a specific directory\n",
        "zipobject.extractall(work_dir)\n",
        "\n",
        "# Display the contents of the extracted zip\n",
        "display_folders(work_dir)\n",
        "\n",
        "# List all sport sessions\n",
        "session_files = []\n",
        "for filename in os.listdir(os.path.join(work_dir, \"Sport-sessions\")):\n",
        "  if filename.endswith(\".json\"):\n",
        "    session_files.append(os.path.join(work_dir, \"Sport-sessions\", filename))\n",
        "\n",
        "# List all gps-data files\n",
        "gps_data_files = []\n",
        "for filename in os.listdir(os.path.join(work_dir, \"Sport-sessions\", \"GPS-data\")):\n",
        "  if filename.endswith(\".json\"):\n",
        "    gps_data_files.append(os.path.join(work_dir, \"Sport-sessions\", \"GPS-data\", filename))\n"
      ],
      "metadata": {
        "id": "8YuLxMtzODGX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load all Sport Sessions\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def process_features(features, id):\n",
        "  \"\"\"\n",
        "  Function to extract and flatten features data, returning the features as a dictionary\n",
        "  We will use this function to extract and flatten data in the features field\n",
        "  Each feature has specific metrics and data points : weather, location,\n",
        "  A list of fastest segments is provided separately as a list of dictionaries.\n",
        "\n",
        "  Args:\n",
        "    features: list of features\n",
        "    id: id of the current session file\n",
        "  Return:\n",
        "    feature_values: dictionary of values of interest extracted from each relevant feature\n",
        "    fastest_segments: list of segments enriched by the sport session id\n",
        "  \"\"\"\n",
        "  feature_values = {}\n",
        "  segments = []\n",
        "  for feature in features:\n",
        "    if feature[\"type\"] == \"fastest_segments\":\n",
        "      fastest_segments = feature[\"attributes\"][\"segments\"]\n",
        "      segments = extract_fastest_segments(id, fastest_segments)\n",
        "      continue\n",
        "    if feature[\"type\"] not in features_to_load:\n",
        "      continue\n",
        "    for key, value in feature[\"attributes\"].items():\n",
        "      if isinstance(value, dict):\n",
        "        # We will not support the embedding json object here\n",
        "        continue\n",
        "      if key not in supported_feature_attributes:\n",
        "        # We are not interested in this data dimension for now\n",
        "        continue\n",
        "      feature_values[key]=value\n",
        "  return feature_values, segments\n",
        "\n",
        "def extract_fastest_segments(id, array_of_segments):\n",
        "  \"\"\"\n",
        "  Retrieve the list of fastest segments beneath the features record\n",
        "  It has the form\n",
        "\n",
        "\n",
        "  Args:\n",
        "    array_of_segments: the json array having the list of segments\n",
        "    id: id of the sport session\n",
        "  \"\"\"\n",
        "  segments = []\n",
        "  for segment in array_of_segments:\n",
        "    segment[\"id\"] = id\n",
        "    segments.append(segment)\n",
        "  return segments\n",
        "\n",
        "# Initialize empty DataFrame to store the sport sessions and the fastest segments\n",
        "sessions_df = pd.DataFrame()\n",
        "fastest_segments_df = pd.DataFrame()\n",
        "# Read each JSON file, process features, and append data to the dataframe\n",
        "try:\n",
        "  for filename in session_files:\n",
        "    with open(filename, \"r\") as f:\n",
        "      data = json.load(f)\n",
        "      # Extract core data\n",
        "      loaded_data = {}\n",
        "      for col in top_level_fields:\n",
        "        loaded_data[col] = data[col]\n",
        "      # Process features and get a dictionary of feature values\n",
        "      feature_values, segments = process_features(data[\"features\"], data[\"id\"])\n",
        "      loaded_data.update(feature_values)\n",
        "      current_row_df = pd.DataFrame.from_dict(loaded_data, orient='index')\n",
        "      sessions_df = pd.concat([sessions_df, current_row_df.T], ignore_index=True)\n",
        "\n",
        "      current_segments_df = pd.DataFrame.from_dict(segments)\n",
        "      fastest_segments_df = pd.concat([fastest_segments_df, current_segments_df], ignore_index=True)\n",
        "except Exception as e:\n",
        "    print(f\"Error processing file '{filename}': {e}\")\n",
        "fastest_segments_df"
      ],
      "metadata": {
        "id": "9ACrzA3_ZuG5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Handle non provided values\n",
        "# Some features are not present in all sessions like temperature or humidity,\n",
        "# which lead to NaN fields\n",
        "nan_columns = sessions_df.columns[sessions_df.isnull().any()]\n",
        "if len(nan_columns) > 0:\n",
        "  print('data dimensions with NaN values: ', end=' ')\n",
        "  print(' '.join(nan_columns))\n",
        "\n",
        "# Replace them with a predefined sentinel value\n",
        "sentinel_value = -99999\n",
        "sessions_df.fillna(sentinel_value, inplace=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EBwZUjhqYyNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convert all time-related columns to appropriate values\n",
        "\n",
        "import datetime\n",
        "\n",
        "time_cols = ['start_time', 'end_time', 'created_at', 'updated_at']\n",
        "\n",
        "# Convert time columns to UTC\n",
        "sessions_df[time_cols] = sessions_df[time_cols].apply(\n",
        "    lambda col: pd.to_datetime(col, unit='ms', utc=True), axis=1\n",
        ")\n",
        "fastest_segments_df['started_at'] = pd.to_datetime(fastest_segments_df['started_at'], unit='ms', utc=True)\n",
        "# Convert all duration to seconds instead of milliseconds\n",
        "duration_cols = ['duration', 'pause', 'start_time_timezone_offset', 'end_time_timezone_offset' ]\n",
        "for col in duration_cols:\n",
        "  sessions_df[col] = sessions_df[col] / 1000\n",
        "fastest_segments_df['duration'] = fastest_segments_df['duration'] / 1000\n",
        "\n",
        "fastest_segments_df.head()"
      ],
      "metadata": {
        "id": "BhB6AwAlIoz3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Compute some statistics from all sport sessions\n",
        "sessions_df.describe()\n"
      ],
      "metadata": {
        "id": "IS_bua1JUrXg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "cellView": "form",
        "outputId": "ac730f60-28c5-4bd2-a7e8-f709d69cbadf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          version      duration       pause     calories  dehydration_volume  \\\n",
              "count  137.000000    137.000000  137.000000   137.000000          137.000000   \n",
              "mean     6.145985   2891.111869    1.141248   897.700730         1124.489051   \n",
              "std      4.612228   1298.565837    3.135842   277.689955          404.723619   \n",
              "min      3.000000    446.688000    0.000000   137.000000          159.000000   \n",
              "25%      4.000000   2124.474000    0.000000   679.000000          817.000000   \n",
              "50%      5.000000   2660.042000    0.000000   891.000000         1084.000000   \n",
              "75%      7.000000   3398.190000    1.214000  1086.000000         1358.000000   \n",
              "max     47.000000  13905.235000   27.974000  1562.000000         2163.000000   \n",
              "\n",
              "       start_time_timezone_offset  end_time_timezone_offset   temperature  \\\n",
              "count                  137.000000                137.000000    137.000000   \n",
              "mean                  5045.255474               5045.255474  -1446.489051   \n",
              "std                   1771.173207               1771.173207  12039.451583   \n",
              "min                   3600.000000               3600.000000 -99999.000000   \n",
              "25%                   3600.000000               3600.000000      8.000000   \n",
              "50%                   3600.000000               3600.000000     14.000000   \n",
              "75%                   7200.000000               7200.000000     17.000000   \n",
              "max                   7200.000000               7200.000000     34.000000   \n",
              "\n",
              "         wind_speed  wind_direction      humidity  start_latitude  \\\n",
              "count    137.000000      137.000000    137.000000      137.000000   \n",
              "mean   -1445.218978    -1241.861314  -1391.189781       43.654765   \n",
              "std    12039.608435    12064.753013  12046.216335        0.380097   \n",
              "min   -99999.000000   -99999.000000 -99999.000000       43.564260   \n",
              "25%        8.000000      130.000000     59.000000       43.635475   \n",
              "50%       13.000000      260.000000     71.000000       43.635635   \n",
              "75%       19.000000      290.000000     80.000000       43.635750   \n",
              "max       55.000000      350.000000    100.000000       48.059555   \n",
              "\n",
              "           distance  elevation_gain  elevation_loss  \n",
              "count    137.000000      137.000000      137.000000  \n",
              "mean    7789.496350       25.547445       26.182482  \n",
              "std     2389.745034       17.380250       17.373162  \n",
              "min     1189.000000        0.000000        0.000000  \n",
              "25%     6015.000000       15.000000       15.000000  \n",
              "50%     7594.000000       26.000000       26.000000  \n",
              "75%     9422.000000       33.000000       32.000000  \n",
              "max    19002.000000      126.000000      131.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d27a50f-26f3-4ad9-b7a3-4f620219f93a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>version</th>\n",
              "      <th>duration</th>\n",
              "      <th>pause</th>\n",
              "      <th>calories</th>\n",
              "      <th>dehydration_volume</th>\n",
              "      <th>start_time_timezone_offset</th>\n",
              "      <th>end_time_timezone_offset</th>\n",
              "      <th>temperature</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>humidity</th>\n",
              "      <th>start_latitude</th>\n",
              "      <th>distance</th>\n",
              "      <th>elevation_gain</th>\n",
              "      <th>elevation_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>137.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.145985</td>\n",
              "      <td>2891.111869</td>\n",
              "      <td>1.141248</td>\n",
              "      <td>897.700730</td>\n",
              "      <td>1124.489051</td>\n",
              "      <td>5045.255474</td>\n",
              "      <td>5045.255474</td>\n",
              "      <td>-1446.489051</td>\n",
              "      <td>-1445.218978</td>\n",
              "      <td>-1241.861314</td>\n",
              "      <td>-1391.189781</td>\n",
              "      <td>43.654765</td>\n",
              "      <td>7789.496350</td>\n",
              "      <td>25.547445</td>\n",
              "      <td>26.182482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.612228</td>\n",
              "      <td>1298.565837</td>\n",
              "      <td>3.135842</td>\n",
              "      <td>277.689955</td>\n",
              "      <td>404.723619</td>\n",
              "      <td>1771.173207</td>\n",
              "      <td>1771.173207</td>\n",
              "      <td>12039.451583</td>\n",
              "      <td>12039.608435</td>\n",
              "      <td>12064.753013</td>\n",
              "      <td>12046.216335</td>\n",
              "      <td>0.380097</td>\n",
              "      <td>2389.745034</td>\n",
              "      <td>17.380250</td>\n",
              "      <td>17.373162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>446.688000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>-99999.000000</td>\n",
              "      <td>-99999.000000</td>\n",
              "      <td>-99999.000000</td>\n",
              "      <td>-99999.000000</td>\n",
              "      <td>43.564260</td>\n",
              "      <td>1189.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2124.474000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>679.000000</td>\n",
              "      <td>817.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>43.635475</td>\n",
              "      <td>6015.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>2660.042000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>43.635635</td>\n",
              "      <td>7594.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>3398.190000</td>\n",
              "      <td>1.214000</td>\n",
              "      <td>1086.000000</td>\n",
              "      <td>1358.000000</td>\n",
              "      <td>7200.000000</td>\n",
              "      <td>7200.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>43.635750</td>\n",
              "      <td>9422.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>13905.235000</td>\n",
              "      <td>27.974000</td>\n",
              "      <td>1562.000000</td>\n",
              "      <td>2163.000000</td>\n",
              "      <td>7200.000000</td>\n",
              "      <td>7200.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>48.059555</td>\n",
              "      <td>19002.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>131.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d27a50f-26f3-4ad9-b7a3-4f620219f93a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d27a50f-26f3-4ad9-b7a3-4f620219f93a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d27a50f-26f3-4ad9-b7a3-4f620219f93a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b9bc6a2-5100-477b-900e-e7a09b35b64b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b9bc6a2-5100-477b-900e-e7a09b35b64b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b9bc6a2-5100-477b-900e-e7a09b35b64b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"sessions_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"version\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.94141340791262,\n        \"min\": 3.0,\n        \"max\": 137.0,\n        \"samples\": [\n          6.145985401459854,\n          5.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4416.921105995583,\n        \"min\": 137.0,\n        \"max\": 13905.235,\n        \"samples\": [\n          2891.1118686131385,\n          2660.042,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pause\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.70723372623389,\n        \"min\": 0.0,\n        \"max\": 137.0,\n        \"samples\": [\n          137.0,\n          1.1412481751824817,\n          27.974\n        ],\n        \"num_unique_values\": 6,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"calories\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 504.23402509579205,\n        \"min\": 137.0,\n        \"max\": 1562.0,\n        \"samples\": [\n          137.0,\n          897.7007299270073,\n          1086.0\n        ],\n        \"num_unique_values\": 7,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dehydration_volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 683.7233565798251,\n        \"min\": 137.0,\n        \"max\": 2163.0,\n        \"samples\": [\n          1124.4890510948906,\n          1084.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_time_timezone_offset\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2447.7410674862376,\n        \"min\": 137.0,\n        \"max\": 7200.0,\n        \"samples\": [\n          5045.255474452555,\n          7200.0,\n          1771.1732071824972\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_time_timezone_offset\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2447.7410674862376,\n        \"min\": 137.0,\n        \"max\": 7200.0,\n        \"samples\": [\n          5045.255474452555,\n          7200.0,\n          1771.1732071824972\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36159.11179872734,\n        \"min\": -99999.0,\n        \"max\": 12039.451583364918,\n        \"samples\": [\n          -1446.4890510948906,\n          14.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wind_speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36160.14757646911,\n        \"min\": -99999.0,\n        \"max\": 12039.608434684225,\n        \"samples\": [\n          -1445.2189781021898,\n          13.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wind_direction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36211.69890243341,\n        \"min\": -99999.0,\n        \"max\": 12064.753013111764,\n        \"samples\": [\n          -1241.8613138686133,\n          260.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36172.31862511985,\n        \"min\": -99999.0,\n        \"max\": 12046.216335145658,\n        \"samples\": [\n          -1391.1897810218977,\n          71.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38.240793005428245,\n        \"min\": 0.38009680582634436,\n        \"max\": 137.0,\n        \"samples\": [\n          43.654764658668235,\n          43.635635,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6014.57589536184,\n        \"min\": 137.0,\n        \"max\": 19002.0,\n        \"samples\": [\n          7789.496350364963,\n          7594.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elevation_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.84291184942959,\n        \"min\": 0.0,\n        \"max\": 137.0,\n        \"samples\": [\n          25.547445255474454,\n          26.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elevation_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53.92715818633665,\n        \"min\": 0.0,\n        \"max\": 137.0,\n        \"samples\": [\n          26.182481751824817,\n          26.0,\n          137.0\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sessions_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8DgTiDwTgdu",
        "outputId": "97b65cd9-9d2a-4f65-be6e-b4fe27fba647"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "version                                     int64\n",
              "duration                                  float64\n",
              "pause                                     float64\n",
              "calories                                    int64\n",
              "dehydration_volume                          int64\n",
              "start_time_timezone_offset                float64\n",
              "end_time_timezone_offset                  float64\n",
              "start_time                    datetime64[ns, UTC]\n",
              "end_time                      datetime64[ns, UTC]\n",
              "created_at                    datetime64[ns, UTC]\n",
              "updated_at                    datetime64[ns, UTC]\n",
              "id                                         object\n",
              "sport_type_id                              object\n",
              "temperature                               float64\n",
              "wind_speed                                float64\n",
              "wind_direction                            float64\n",
              "humidity                                  float64\n",
              "start_latitude                            float64\n",
              "start_longitude                            object\n",
              "distance                                    int64\n",
              "average_speed                              object\n",
              "average_pace                               object\n",
              "max_speed                                  object\n",
              "elevation_gain                              int64\n",
              "elevation_loss                              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load  sport sesssions in the postgresql table\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "\n",
        "# Replace with your connection details\n",
        "conn = psycopg2.connect(conn_string)\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Define the unique columns for checking existing data\n",
        "unique_cols = ['id']  # Adjust based on your unique identifier\n",
        "\n",
        "try:\n",
        "  # Fetch existing data for comparison\n",
        "  existing_data_sql = f\"SELECT {', '.join(unique_cols)} FROM {sessions_table};\"\n",
        "  cur.execute(existing_data_sql)\n",
        "  existing_data = pd.DataFrame(cur.fetchall(), columns=unique_cols)\n",
        "\n",
        "  # Merge dataframes to identify new rows\n",
        "  new_data = pd.merge(sessions_df, existing_data, how='left', on=unique_cols, indicator=True)\n",
        "  new_data = new_data[new_data['_merge'] == 'left_only'][sessions_df.columns]\n",
        "\n",
        "  # Insert only new rows into the table\n",
        "  if not new_data.empty:\n",
        "      insert_sql = \"\"\"\n",
        "      INSERT INTO sessions (\n",
        "          version, duration, pause, calories, dehydration_volume,\n",
        "          start_time_timezone_offset, end_time_timezone_offset, start_time, end_time,\n",
        "          created_at, updated_at, id, sport_type_id, temperature, wind_speed, wind_direction,\n",
        "          humidity, start_latitude, start_longitude, distance, average_speed,\taverage_pace,\tmax_speed,\n",
        "          elevation_gain,\televation_loss)\n",
        "          VALUES (%s, %s, %s, %s, %s, %s, %s, %s,%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
        "      \"\"\"\n",
        "\n",
        "      data_tuples = new_data.to_records(index=False)\n",
        "      cur.executemany(insert_sql, data_tuples)\n",
        "  # Commit changes and close connection\n",
        "  conn.commit()\n",
        "  print(\"Data inserted successfully!\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"failed to load data into the sessions table: {e}\")\n",
        "\n",
        "cur.close()\n",
        "conn.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "F77YtcWB2Qhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display the location of all Sport Sessions on a map\n",
        "import folium\n",
        "from folium import plugins\n",
        "sessions_map = folium.Map(location=[43.6047, 1.4442], zoom_start=5) # My main location, TODO, get a centroid of all points.\n",
        "sessions_cl = plugins.MarkerCluster().add_to(sessions_map)\n",
        "# Loop through the dataframe and add the location of each session to the cluster\n",
        "for lat, lng, label in zip(sessions_df.start_latitude, sessions_df.start_longitude, sessions_df.start_time):\n",
        "  folium.Marker(\n",
        "      location=[lat, lng],\n",
        "      popup=label,\n",
        "      icon=None\n",
        "  ).add_to(sessions_cl)\n",
        "\n",
        "\n",
        "# Display the map\n",
        "sessions_map"
      ],
      "metadata": {
        "id": "bFLiLdM2rA4B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Export the  extracted sport sessions in an excel sheet\n",
        "from google.colab import files\n",
        "\n",
        "excel_filename = 'runtastic_data.xlsx'\n",
        "excel_filepath = os.path.join(work_dir, excel_filename)\n",
        "sessions_df.to_excel(excel_filepath)\n",
        "files.download(excel_filepath)\n"
      ],
      "metadata": {
        "id": "ktxRfIjDB54K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}